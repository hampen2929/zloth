# tazuna Next Gen（刷新提案）

## 目的（コンセプトの言語化）

### コンセプト（ユーザー提供）
- 人間はAIにできず人間しかできないことだけをする
- 人間がやることを最小限、一目瞭然にする
- AIが何をやっていることを一目瞭然で確認できるようにする
- ソフトウェアエンジニアリングにおける最高のUI/UX
- パソコンでの開発体験を最高にする
- AIの進歩はAI coding toolに任せて、開発体験/開発効率の向上に努める

### これをtazunaの役割に落とす（結論）
**tazuna Next Gen = “AI Coding Tool を束ね、開発者が意思決定だけに集中できるコックピット”**

- **AIは**: 収集・計画・実装・検証（テスト/静的解析）・差分生成・PR作成までを自動化する
- **人間は**: 目的・制約・リスク許容度の提示、結果の採用/却下、最終承認だけを行う
- **UIは**: AIの行動（何を・いつ・なぜ・どこまで）を“工程”として可視化し、レビュー/採用の判断に必要な情報だけを最短距離で提示する

---

## 現状（As-Is）

### プロダクト/機能（読み取れる現状）
- **Web UI（Next.js）**でタスクを作成し、複数モデルの**並列Run**を実行して、パッチ/差分/ログを見て、採用Runから**PRを作成**できる
- **API（FastAPI）**はTask/Message/Run/PRを保持し、Runはin-memory queueで非同期実行（v0.1）
- **PatchAgent**は「ファイル収集→プロンプト生成→LLM→パッチ抽出」の流れでUnified diffを生成
- v0.2以降で「Docker sandboxでのコマンド実行」「Review/Meta Agent」等が計画されている

### 体験上の制約（ドキュメントから）
- **人間の手順が多い/分散しやすい**: 設定不足（モデル/GitHub）時の詰まり、PR作成後の導線、比較のしづらさ
- **AIが今何をしているかが粗い**: “RUNNING”は分かるが、工程の見える化（進捗・次の一手）が不足
- **比較価値が活ききっていない**: マルチモデルの結果が「カードの羅列」に寄り、意思決定を支援する比較UIが弱い
- **PC開発体験の最適化が未完成**: キーボード主導（コマンドパレット/タブ切替/ジャンプ）や情報密度の最適化がこれから

---

## あるべき（To-Be / North Star）

### 北極星体験（ユーザーが感じる“最高”の状態）
- ユーザーは「何を達成したいか」を書き、必要なら制約（方針/期限/禁止事項）を指定するだけ
- tazunaは**最適な実行器（複数モデル/CLI/サンドボックス）**で自動実行し、工程がタイムラインで見える
- 結果は「採用判断」に必要な情報（変更点・影響範囲・テスト結果・リスク・差分）に圧縮され、**一目で採否を決められる**
- “採用”を押すと、PR/更新/再実行/比較が自然に繋がり、**迷子が発生しない**

### 体験原則（UI/UXの非交渉条件）
1. **Human-only を明確化**: 人間の入力は「目的」「制約」「承認」だけに寄せる（それ以外はAI/自動化）
2. **一目瞭然**: 画面は常に「今/次/必要な操作」を先頭に表示し、詳細は折り畳む（Progressive disclosure）
3. **AIの透明性**: “工程”・“根拠”・“成果物”・“失敗理由”・“次の一手”を同じ場所で提示する
4. **PCファースト**: キーボード中心、検索/ジャンプ中心、情報密度を最適化（ラップトップでも生産性）
5. **AI進歩は外部に委任**: tazunaはモデル性能競争をしない。実行器を差し替え可能にし、**コックピット体験を磨く**

---

## ギャップ（As-Is → To-Be）

| 論点 | As-Is | To-Be | ギャップ |
|---|---|---|---|
| 人間の操作量 | 設定/選択/比較/PR導線で迷い得る | 入力は目的・制約・承認に集約 | 手順の削減、詰まりの解消、既定値/プリセット |
| 透明性（AIが何をしているか） | 状態/ログ中心で工程が見えにくい | 工程タイムライン＋成果物（差分/テスト）中心 | 進捗イベント化、要約、失敗分類と推奨アクション |
| 比較/意思決定 | 結果カードの並び | 比較ビュー（品質/影響/リスク）で“採用”を支援 | 比較UI、採用候補ピン、スコアリング（Review） |
| PC開発体験 | ベースはあるが弱い | キーボード主導＋ジャンプ＋高密度レビュー | コマンドパレット、ショートカット、diffナビ |
| 実行/検証の自動化 | パッチ生成が中心 | 実装→検証→PRまでを標準化 | Docker sandbox、検証パイプライン、実行器拡張 |
| 情報設計 | 情報が分散しやすい | 「今/次/判断材料」に圧縮 | 画面構造の再設計、空状態/復旧導線 |

---

## やること（優先度付き）

以下は「コンセプトに直結し、開発体験の質を最大化する順」での提案です。P0は“詰まり解消と透明性の土台”、P1は“比較と意思決定”、P2は“PC生産性の最大化”、P3は“継続的な伸びしろ”です。

### P0（最優先）: “迷わない/見える”を成立させる

- **P0-1: セットアップ/空状態の完全解消（Guided Onboarding）**
  - **狙い**: 「何をすれば動くか」をUIが常に提示し、詰まりをゼロに近づける
  - **やること**:
    - Homeに「チェックリスト式のセットアップ状態」（GitHub / Model / Repo）を常設
    - 設定不足時は、操作点の横に**不足条件＋SettingsへのCTA**を表示（押して失敗をなくす）
    - “最初の成功体験”テンプレ（例: docs更新、lint修正）を用意

- **P0-2: Runの“工程”可視化（AI Activity Timeline）**
  - **狙い**: “AIが今何をしているか”を状態ではなく工程として見せる
  - **やること**:
    - Runに「工程イベント（step）」を保存・配信（例: Workspace準備/解析/生成/パッチ抽出/検証/PR）
    - UIはRunカードのヘッダーで「今の工程/経過時間/次に起きること」を表示
    - 失敗は分類（auth/network/rate_limit/conflict/test等）し、**推奨アクション**を提示

- **P0-3: 採用判断を最短化する“結果要約”の標準化**
  - **狙い**: 人間が見るべき情報を固定し、レビュー時間を短縮
  - **やること**:
    - Runの出力を「変更ファイル/影響範囲/テスト結果/リスク/注意点」の枠に正規化
    - Summary/Diff/Logsの順番と意味を統一し、重要情報を先頭に集約

### P1: “比較”を武器にして意思決定を支援する

- **P1-1: マルチモデル比較ビュー（Decision UI）**
  - **狙い**: tazunaの差別化（比較）を“採用判断の支援”として完成させる
  - **やること**:
    - 同一指示のRunを横並びで比較（要約/変更量/失敗理由/テスト結果）
    - “採用候補”ピン留め、差分の切替、ファイル変更一覧の比較

- **P1-2: Review/Meta Agent を“スコアと推薦”として実装**
  - **狙い**: 人間の判断コストをさらに下げる（ただし最終承認は人間）
  - **やること**:
    - 観点（可読性/保守性/変更量/リスク/テスト）でスコアと短い推薦理由を生成
    - 推薦は“押し付け”ではなく、比較ビュー内の補助情報に留める

- **P1-3: Diff体験の刷新（ファイル一覧/ジャンプ/折り畳み）**
  - **狙い**: レビューを“速く/疲れず/迷わず”できる状態にする
  - **やること**:
    - 変更ファイル一覧→クリックで該当hunkへジャンプ
    - 大差分はデフォルト折り畳み、Split/Unified切替、コピー/ダウンロード

### P2: PC開発体験を“最高”に寄せる（Keyboard-first）

- **P2-1: コマンドパレット（Cmd/Ctrl+K）とショートカット体系**
  - **狙い**: マウス移動を減らし、作業速度を上げる
  - **やること**:
    - 「新規タスク/実行/比較/採用/PR/再実行/設定/検索」をパレットで統合
    - タブ切替、ログ検索、ファイルジャンプのショートカットを整備

- **P2-2: タスク探索性（検索/フィルタ/ピン/グルーピング）**
  - **狙い**: 長期運用での“探せない”を無くす
  - **やること**:
    - タイトル/Repo/ステータスで検索・フィルタ
    - 日付グルーピング、ピン留め、最近使ったRepoの高速導線

- **P2-3: 情報密度の最適化（ラップトップ最適）**
  - **狙い**: “一画面で判断できる量”を増やし、スクロール/遷移を減らす
  - **やること**:
    - Runカードのヘッダーに重要情報を集約（成功/失敗/警告、変更量、工程、時間）
    - 詳細は折り畳み、必要時だけ展開

### P3: 自動化の深掘り（AI coding toolに任せつつ体験を伸ばす）

- **P3-1: コマンド実行（Docker sandbox）で“検証まで自動化”**
  - **狙い**: 生成→検証→採用までを標準パイプライン化し、信頼性を上げる
  - **やること**:
    - lint/test/typecheckをRunの工程として組み込み、結果をUIで要約表示
    - 失敗時は最短の復旧導線（再実行/設定/別実行器）を提示

- **P3-2: 実行器（Executor）プラグイン化の明確化**
  - **狙い**: AIの進歩を外部に任せ、tazunaは“統合と体験”に集中する
  - **やること**:
    - 既存のPatchAgentに加え、CLI系/将来のツールを差し替え可能にする
    - 出力を共通スキーマ（工程イベント、成果物、コスト、警告）に正規化

- **P3-3: 観測性（Observability）のUX**
  - **狙い**: “何が起きたか”を後から追える（チーム/長期運用）
  - **やること**:
    - Runのタイムライン、成果物、PRまでを時系列で俯瞰できるビュー
    - 重要イベントの監査ログ（誰が採用したか、何を適用したか）

---

## 成功指標（KPI）
- **セットアップ完了率**: 初回起動からモデル/認証まで完了できた割合
- **初回PR作成までの時間**: 初見ユーザーがPRを作るまでの中央値
- **“迷い”の減少**: 設定不足/入力不足でのエラー発生率、離脱率
- **比較の利用率**: 比較ビューの起動率、採用候補ピン率
- **透明性の体感**: 実行中に“今何をしているか分からない”フィードバックの減少

---

## 実行計画（おすすめの進め方）

### 1) まずP0だけを短期間でやり切る
P0は「体験の土台」です。ここが成立すると、以降のP1/P2の投資効率が跳ね上がります。

### 2) 次にP1で“比較価値”を完成させる
tazunaの価値を最も強く体感できる部分なので、早めに“採用のしやすさ”まで到達させます。

### 3) P2で“PC最強”へ
コマンドパレット/ショートカット/探索性は、日常的な継続利用で効いてきます。

### 4) P3で“検証まで自動化”を仕上げる
生成だけでなく、検証結果が常に付くことで「人間の不安」を減らし、承認が速くなります。

